{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, sampler\nfrom torchvision import transforms, utils\nfrom PIL import Image\nfrom glob import glob\n#create dataset\nclass HeadCtDS(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.df = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.images_path = sorted(glob(os.path.join(root_dir, '*')))\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image_path = self.images_path[idx]\n        image = Image.open(image_path).convert('RGB')\n        label = self.df.iloc[idx][-1]\n        label = np.array(label)\n        if self.transform:\n            image = self.transform(image)\n        return image, label        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(torch.cuda.is_available())     \ntorch.cuda.current_device()   \ntorch.cuda.get_device_name(0)\ntorch.cuda.empty_cache()     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dataset and load data\nimg_dir = \"../input/head_ct/head_ct/\"\ncsv_file = \"../input/labels.csv\"\n# df = pd.read_csv(csv_file)\n# df.head()\n# df.iloc[0][-1]\ndataset = HeadCtDS(csv_file, img_dir, transform=transforms.Compose([transforms.Resize((224,224)),\n                                                                    transforms.RandomGrayscale(),\n                                                                    transforms.RandomHorizontalFlip(),\n                                                                    transforms.RandomRotation(10),\n                                                                    transforms.ToTensor(), \n                                                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train 80%, val 20%\nDivide dataset using samplers\n'''\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nval_split = 0.2\nsplit = int(val_split*dataset_size)\nshuffle_dataset = True\nrandom_seed = 1337\nif shuffle_dataset:\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\nprint(len(train_indices), len(val_indices))\n# train_indices\ntrain_sampler = sampler.SubsetRandomSampler(train_indices)\nvalid_sampler = sampler.SubsetRandomSampler(val_indices)\ntrainloader = DataLoader(dataset, batch_size=10, sampler=train_sampler)\nvalidloader = DataLoader(dataset, batch_size=10, sampler=valid_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainiter = iter(trainloader)\nimages, label = trainiter.next()\nimages.shape\nplt.figure(figsize = (50,50))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(np.array(images[i]).transpose((1,2,0)), cmap='gray')\nprint(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a model\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(2, 2))\n        self.layer2 = nn.Sequential(nn.Conv2d(32, 32, 3),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(2, 2),\n                                   nn.BatchNorm2d(32))\n        self.layer3 = nn.Sequential(nn.Conv2d(32, 64, 3),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(2, 2))\n        self.fc1 = nn.Linear(64*26*26, 64)\n        self.dropout = nn.Dropout(0.5)\n        self.bn = nn.BatchNorm1d(64)\n        self.fc2 = nn.Linear(64, 2)\n        self.prob = nn.LogSoftmax(dim=1)\n    \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(-1, 64*26*26)\n        out = F.relu(self.fc1(out))\n        out = self.bn(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.prob(out)\n        return out\n    \nmodel = Net().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size = (3, 224, 224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loss and optimizer\nimport torch.optim as optim\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train and validate the model\nnum_epochs = 100\ntrain_loss_list = []\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n    train_total = 0\n    train_correct = 0\n    \n    model.train(True)\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs).cuda()\n            t_loss = criterion(outputs, labels)\n        t_loss.backward()\n        optimizer.step()\n        train_loss += t_loss.item()\n        \n        #train_accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n    train_acc = (100*train_correct/train_total)\n    train_loss = train_loss/len(trainloader)\n    train_acc_list.append(train_acc)\n    train_loss_list.append(train_loss)\n    \n    model.train(False)\n    model.eval()\n    val_total = 0\n    val_correct = 0\n    \n    for i, data in enumerate(validloader, 0):\n        inputs, labels = data\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n        optimizer.zero_grad()\n        with torch.no_grad():\n            outputs = model(inputs).cuda()\n            v_loss = criterion(outputs, labels)\n        val_loss += v_loss.item()\n            \n        #val_accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        val_total += labels.size(0)\n        val_correct += (predicted == labels).sum().item()\n    val_acc = (100*val_correct/val_total)\n    val_acc_list.append(val_acc)\n    val_loss = val_loss/ len(validloader)\n    val_loss_list.append(val_loss)\n    print('Epoch: {} - train_loss: {} - train_acc: {} - val_loss: {} - val_acc: {} '.format(epoch, train_loss, train_acc, val_loss, val_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [i for i in range(100)]\nplt.title('Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Valid'], loc = 'upper left')\nplt.plot(epochs, train_loss_list, 'r', epochs, val_loss_list, 'b')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(epochs, train_acc_list, 'r', epochs, val_acc_list, 'b')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}